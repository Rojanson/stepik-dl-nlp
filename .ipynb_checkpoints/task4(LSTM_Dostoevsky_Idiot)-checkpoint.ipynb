{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfab8f2d-22b8-4651-9411-7a68a7989eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "import dlnlputils\n",
    "from dlnlputils.data import tokenize_corpus, build_vocabulary\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea577f25-ce6e-46e5-858c-184e15a80a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если Вы запускаете ноутбук на colab или kaggle, добавьте в начало пути ./stepik-dl-nlp\n",
    "with open('datasets/Dostoevskiy_IDIOT.txt', encoding=\"utf8\") as input_file:\n",
    "    lovecraft_text = input_file.read()\n",
    "lovecraft_text = lovecraft_text.replace('\\n', ' ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0224107d-80d0-4a43-bc6f-276394a20d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13734"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_re = re.compile(r'[А-Я].*?[\\.!?]', re.M)\n",
    "handled_text = t_re.findall(lovecraft_text)\n",
    "len(handled_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8467a051-24f5-4e98-bf62-c1c03a2569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 85\n",
    "\n",
    "t_re = re.compile(r'[А-Я].*?[,]', re.M)\n",
    "\n",
    "for i in range(len(handled_text)):\n",
    "    handled_text[i] = ' ' + handled_text[i]\n",
    "    if len(handled_text[i]) > MAX_LENGTH:\n",
    "        end_word_index = MAX_LENGTH\n",
    "        if handled_text[i][MAX_LENGTH - 1] != ' ':\n",
    "            end_word_index = handled_text[i].find(' ', MAX_LENGTH - 1)\n",
    "        handled_text[i] = handled_text[i][:end_word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df7b349f-11fb-4b7d-9619-7852b5da8ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' В конце ноября, в оттепель, часов в девять утра, поезд Петербургско-Варшавской железной',\n",
       " ' Было так сыро и туманно, что насилу рассвело; в десяти шагах, вправо и влево от дороги,',\n",
       " ' Из пассажиров были и возвращавшиеся из-за границы; но более были наполнены отделения',\n",
       " ' Все, как водится, устали, у всех отяжелели за ночь глаза, все назяблись, все лица были',\n",
       " ' В одном из вагонов третьего класса, с рассвета, очутились друг против друга, у самого',\n",
       " ' Если б они оба знали один про другого, чем они особенно в эту минуту замечательны, то,',\n",
       " ' Один из них был небольшого роста, лет двадцати семи, курчавый и почти черноволосый, ',\n",
       " ' Нос его был широк и сплюснут, лицо скулистое; тонкие губы беспрерывно складывались в',\n",
       " ' Особенно приметна была в этом лице его мертвая бледность, придававшая всей физиономии',\n",
       " ' Он был тепло одет, в широкий, мерлушечий, черный, крытый тулуп, и за ночь не зяб, тогда']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handled_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19ec52be-8d63-4618-96dc-c0363055ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_re = re.compile(r'([^\\.!?]*[\\.!?])', re.M)\n",
    "#handled_text = t_re.findall(lovecraft_text)\n",
    "#len(handled_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3166c0-2754-4519-b836-46a351d611c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens = 127\n"
     ]
    }
   ],
   "source": [
    "#all unique characters go here\n",
    "tokens = list(set(''.join(handled_text)))\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print ('num_tokens =', num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "167fd7ec-8d49-4c3d-a113-152cf652ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa6cb00-7f32-4e4d-9875-a34a53c3ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71519716-4b58-496a-a42f-76e49f85a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(data, token_to_id, max_len=None, dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, data))\n",
    "    data_ix = np.zeros([len(data), max_len], dtype) + token_to_id[' ']\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        line_ix = [token_to_id[c] for c in data[i]]\n",
    "        data_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        data_ix = np.transpose(data_ix)\n",
    "\n",
    "    return data_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "157eb44c-8aff-418a-ac6a-3acb0bc0f0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Все, как водится, устали, у всех отяжелели за ночь глаза, все назяблись, все лица были\n",
      "[ 33  96  44  86  61  33 123  64 123  33  84 100  78   1   2  44  59  61\n",
      "  33  53  44   2  64 118   1  61  33  53  33  84  44  86   0  33 100   2\n",
      "  59 115  86 118  86 118   1  33 103  64  33  85 100  26  83  33  28 118\n",
      "  64 103  64  61  33  84  44  86  33  85  64 103  59  72 118   1  44  83\n",
      "  61  33  84  44  86  33 118   1  14  64  33  72 111 118   1]\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "print(handled_text[3])\n",
    "print(to_matrix(handled_text[3:5], token_to_id)[0])\n",
    "print(len(handled_text[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa9d778-6cee-44bb-8662-fcfb5aa36f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2720cb5-757d-4ee3-9874-9ebc60cd5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "class CharLSTMLoop(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens, emb_size=64, hidden_size=512):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.LSTM = nn.LSTM(input_size=emb_size, hidden_size=hidden_size, num_layers=2, batch_first=True)\n",
    "        self.hid_to_logits = nn.Linear(hidden_size, num_tokens)\n",
    "        \n",
    "    def forward(self, x, h=None, c=None):\n",
    "        if h is not None and c is not None:\n",
    "            out_put, (h_new, c_new) = self.LSTM(self.emb(x), (h, c))\n",
    "        else:\n",
    "            out_put, (h_new, c_new) = self.LSTM(self.emb(x))\n",
    "            \n",
    "        next_logits = self.hid_to_logits(out_put)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        \n",
    "        return next_logp, h_new, c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6666ab20-ada7-4135-aaa6-dd3ec08194ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#here i started cell twice(that is why we got 8000 epochs here)\n",
    "MAX_LENGTH = max(map(len, handled_text))\n",
    "\n",
    "#model = CharLSTMLoop()\n",
    "model = model.to(device)\n",
    "#opt = torch.optim.Adam(model.parameters())\n",
    "#history = []\n",
    "\n",
    "#best_loss = 6\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for i in range(4000):\n",
    "    batch_ix = to_matrix(sample(handled_text, 128), token_to_id, max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64).to(device)\n",
    "\n",
    "    logp_seq, _, _ = model(batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]\n",
    "    actual_next_tokens = batch_ix[:, 1:]\n",
    "\n",
    "    loss = -torch.mean(torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None]))\n",
    "\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # train with backprop\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    history.append(loss.cpu().data.numpy())\n",
    "    if (i + 1) % 20 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:25]) > np.mean(history[-25:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a00377d5-c49d-42c7-8928-56af86b9f9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dcf7e05-ea40-42f4-a674-af46b9651e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " А я думал, что уж сказал… Я одно такое письмецо получил, для передучить меня маленькую и тоскую      \n",
      " Он поворотил назад и прямо по дороге, по которой проходил вчера с Евлечением смотря                  \n",
      " Вы не отвечаете мне?                                                                                 \n",
      " Не стоите вы все ничего.                                                                             \n",
      " Если он сейчас не подойдет ко мне, не возьмет меня и не бросит тебя, то бери же его                  \n",
      " Ну, вот, вздор какой!                                                                                \n",
      " В последние десять или двадцать минут он говорил, разгорячившись, громко, нетерпеливою               \n",
      " Настасья Филипповна проходила в эту минуту мимо самых стульев барышень.                              \n",
      " Не могу же я получать эти письма!                                                                    \n",
      " В этом лице… страдания много… – проговорил князь, как бы невольно, как бы сам с собою                \n"
     ]
    }
   ],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [[token_to_id[token] for token in seed_phrase]]\n",
    "    x_sequence = torch.tensor(x_sequence, dtype=torch.int64)\n",
    "    \n",
    "    h_t = None\n",
    "    c_t = None\n",
    "    if len(seed_phrase) > 1:\n",
    "        _, h_t, c_t = model.forward(x_sequence[:, :-1], h_t)\n",
    "    \n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        logp_next, h_t, c_t = model.forward(x_sequence[:, -1].unsqueeze(-1), h_t, c_t)\n",
    "        p_next = F.softmax(logp_next / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        next_ix = np.random.choice(len(tokens), p=p_next[0])\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence[0].data.numpy()])\n",
    "\n",
    "\n",
    "model = model.to('cpu')\n",
    "for _ in range(10):\n",
    "    print(generate_sample(model, seed_phrase=' ', temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33a9e926-7909-40ce-9651-4b58cf739190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Но разъяснив вам, что меня не так-то легко прожить в положение делать.                               \n",
      " Право, всё это как-то нелепо и не может быть.                                                        \n",
      " Не было бы этого, я, может быть, никогда ему не усказала до считать, – вот к делу,                   \n",
      " Ну, уж теперь совсем довольно!                                                                       \n",
      " Тут один Тоцкий.                                                                                     \n",
      " Приличие и чинность чрезвычайные, несмотря на некоторый общий вид семейственности и                  \n",
      " Князь пригласил его садиться.                                                                        \n",
      " Почему она один вдруг встал с себя от удивленный вчерашней верлости, развернуть                      \n",
      " Лизавета Прокофьевна прямо направилась в сторону, противоположную той, в которую направлялись        \n",
      " Если бы вы пожили больше с людьми, а в свете, я надеюсь, вам будут рады, как замечательному          \n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(model, seed_phrase=' ', temperature=0.65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "541c89d7-0c59-4e6d-93fc-38750867b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Doestoevsky.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
